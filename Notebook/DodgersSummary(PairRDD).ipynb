{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a0db71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_SparkContext import init_SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc43f625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark found in your system !!\n",
      "Spark Context and Spark session initialized !!\n"
     ]
    }
   ],
   "source": [
    "sc, spark = init_SparkContext(appName=\"DodgersSummary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24583473",
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficPath = \"D:\\\\Big Data\\\\Notebook\\\\data\\\\Dodgers.data\"\n",
    "gamesPath = \"D:\\\\Big Data\\\\Notebook\\\\data\\\\Dodgers.events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b731c0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4/10/2005 0:00,-1',\n",
       " '4/10/2005 0:05,-1',\n",
       " '4/10/2005 0:10,-1',\n",
       " '4/10/2005 0:15,-1',\n",
       " '4/10/2005 0:20,-1',\n",
       " '4/10/2005 0:25,-1',\n",
       " '4/10/2005 0:30,-1',\n",
       " '4/10/2005 0:35,-1',\n",
       " '4/10/2005 0:40,-1',\n",
       " '4/10/2005 0:45,-1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic = sc.textFile(trafficPath)\n",
    "traffic.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77545d",
   "metadata": {},
   "source": [
    "- Each row represents a five-minute slice of time,\n",
    "- and the second column in the dataset represents the number of cars that passed by in that five-minute slice of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b0d685c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['04/12/05,13:10:00,16:23:00,55892,San Francisco,W 9-8�',\n",
       " '04/13/05,19:10:00,21:48:00,46514,San Francisco,W 4-1�',\n",
       " '04/15/05,19:40:00,21:48:00,51816,San Diego,W 4-0�',\n",
       " '04/16/05,19:10:00,21:52:00,54704,San Diego,W 8-3�',\n",
       " '04/17/05,13:10:00,15:31:00,53402,San Diego,W 6-0�',\n",
       " '04/25/05,19:10:00,21:33:00,36876,Arizona,L 4-2�',\n",
       " '04/26/05,19:10:00,22:00:00,44486,Arizona,L 3-2�',\n",
       " '04/27/05,19:10:00,22:17:00,54387,Arizona,L 6-3�',\n",
       " '04/29/05,19:40:00,22:01:00,40150,Colorado,W 6-3�',\n",
       " '04/30/05,19:10:00,21:45:00,54123,Colorado,W 6-2�']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games = sc.textFile(gamesPath)\n",
    "games.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee95dd81",
   "metadata": {},
   "source": [
    "- It has the start and end time for a game,\n",
    "- the number of folks who actually attended that game,\n",
    "- the opponent that the dodgers played on that day,\n",
    "- and the win/loss infomation along with the score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fdac76",
   "metadata": {},
   "source": [
    "- Now we will start by taking the traffic RDD and pssing it to create a pair RDD.\n",
    "- For a pair RDD we need to have each row or each record represented as a tuple with two elements.\n",
    "\n",
    "- So we will set up a function that can take in a string and extract out two elements from it: the date or the five-minute time slice, and a number representing the traffic that passed by in that five-minute time slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "466f39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "def parseTraffic(row):\n",
    "    DATE_FMT = \"%m/%d/%Y %H:%M\"\n",
    "    row = row.split(\",\")\n",
    "    row[0] = datetime.strptime(row[0], DATE_FMT)\n",
    "    row[1] = int(row[1])\n",
    "    return (row[0], row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a823aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficParsed = traffic.map(parseTraffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6af5b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2005, 4, 10, 0, 0), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 5), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 10), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 15), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 20), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 25), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 30), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 35), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 40), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 45), -1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trafficParsed.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858218a4",
   "metadata": {},
   "source": [
    "- The result is a pair RDD in which each record is tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b264214",
   "metadata": {},
   "source": [
    "### Summarizing Pair RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b302b4c",
   "metadata": {},
   "source": [
    "#### reduceByKey\n",
    "\n",
    "- reduceByKey is similar to the reduce operation that we have seen earlier,\n",
    "- it is used to combine records with the same key in a specified way: Sum, Maximum, Minimum\n",
    "- it need function with 2 arguments\n",
    "- unlike reduce, reduceByKey will not combine the complete record\n",
    "- only combine values with the same key\n",
    "- The operation is a transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f6d348",
   "metadata": {},
   "source": [
    "### Computing a daily trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "893dab49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2005, 4, 10, 0, 0), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 5), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 10), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 15), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 20), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 25), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 30), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 35), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 40), -1),\n",
       " (datetime.datetime(2005, 4, 10, 0, 45), -1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trafficParsed.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67474d6a",
   "metadata": {},
   "source": [
    "- From this RDD we want to go to another RDD which has the date as the key and the total number of cars which passed by on that day as the value.\n",
    "\n",
    "- To do this we first use a map operation that takes the traffic parsed RDD and takes the timestamp which is present in the key and converts it to just the date of that timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58511884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarizing a pair RDD\n",
    "dailyTrend = trafficParsed.map(lambda x: (x[0].date(), x[1]))\\\n",
    "                          .reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6954c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 4, 10), -288),\n",
       " (datetime.date(2005, 4, 11), 5062),\n",
       " (datetime.date(2005, 4, 12), 6822),\n",
       " (datetime.date(2005, 4, 13), 6742),\n",
       " (datetime.date(2005, 4, 14), 6423),\n",
       " (datetime.date(2005, 4, 15), 6459),\n",
       " (datetime.date(2005, 4, 16), 6002),\n",
       " (datetime.date(2005, 4, 17), 5322),\n",
       " (datetime.date(2005, 4, 18), 5600),\n",
       " (datetime.date(2005, 4, 19), 6049)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyTrend.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b7faa",
   "metadata": {},
   "source": [
    "- and this reduceByKey operation will return an RDD in which each record is the date and the value is the total amount of traffic that is passed by the dodgers Stadium on that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9cc5252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 7, 28), 7661),\n",
       " (datetime.date(2005, 7, 29), 7499),\n",
       " (datetime.date(2005, 8, 12), 7287),\n",
       " (datetime.date(2005, 7, 27), 7238),\n",
       " (datetime.date(2005, 9, 23), 7175),\n",
       " (datetime.date(2005, 7, 26), 7163),\n",
       " (datetime.date(2005, 5, 20), 7119),\n",
       " (datetime.date(2005, 8, 11), 7110),\n",
       " (datetime.date(2005, 9, 8), 7107),\n",
       " (datetime.date(2005, 9, 7), 7082)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyTrend.sortBy(lambda x:-x[1]).take(10)   #-x[1] to specify descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c917f",
   "metadata": {},
   "source": [
    "### Merging Pair RDDs\n",
    "\n",
    "- very often you will come across situations where you have data present across two or more RDDs and you need to merge these two RDDs before you can summarize your data.\n",
    "- this is not all that different from a join in SQL\n",
    "- Spark allows you to merge two pair RDDs based on the keys of those RDDs.\n",
    "- Let say you have two RDDs like this which have same keys but different values.\n",
    "- you can merge these two pair RDDs by merging the records which have the same key and then collecting the values in those records into one list.\n",
    "- such operations are called joins.\n",
    "\n",
    "#### Types of joins\n",
    "\n",
    "- join\n",
    "- leftOuterJoin\n",
    "- rightOuterJoin\n",
    "\n",
    "\n",
    "##### Each of these operations is similar to its counterpart in SQL\n",
    "\n",
    "- join: A join merges two pair RDDs and returns a new pair RDD. The new RDD will look at keys from both the RDDs and wherever the keys match it will collect the values. If there is no match for a key, which means that a key exists only in one of the input RDDs then the key is completely dropped.\n",
    "\n",
    "\n",
    "- leftOuterJoin: All the records from the left RDD are returned which means that all the keys from the left RDD are returned and only those keys in the right RDD which have a match to the left RDD are returned.\n",
    "\n",
    "\n",
    "- rightOuterJoin: The rightOuterJoin is just the reverse of the leftOuterJoin, All the keys from the right RDD are returned and only those keys in the left RDD that match the right RDD are returned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e9ba9",
   "metadata": {},
   "source": [
    "- Above we were able to find the top 10 days which had the most amount of traffic passing by the Dodgers Stadium.\n",
    "\n",
    "\n",
    "- It would be interesting to see--- if the Dodgers were playing a game in the stadium on any of these days\n",
    "\n",
    "\n",
    "- To do that we have to join this dataset with another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdd262bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining with games\n",
    "\n",
    "def parsedGames(row):\n",
    "    DATE_FMT = \"%m/%d/%y\"\n",
    "    row = row.split(\",\")\n",
    "    row[0] = datetime.strptime(row[0], DATE_FMT).date()\n",
    "    return (row[0], row[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "001c0a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 4, 12), 'San Francisco'),\n",
       " (datetime.date(2005, 4, 13), 'San Francisco'),\n",
       " (datetime.date(2005, 4, 15), 'San Diego'),\n",
       " (datetime.date(2005, 4, 16), 'San Diego'),\n",
       " (datetime.date(2005, 4, 17), 'San Diego'),\n",
       " (datetime.date(2005, 4, 25), 'Arizona'),\n",
       " (datetime.date(2005, 4, 26), 'Arizona'),\n",
       " (datetime.date(2005, 4, 27), 'Arizona'),\n",
       " (datetime.date(2005, 4, 29), 'Colorado'),\n",
       " (datetime.date(2005, 4, 30), 'Colorado')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamesParsed = games.map(parsedGames)\n",
    "gamesParsed.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94fa29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyTrendCombined = dailyTrend.leftOuterJoin(gamesParsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5bb87e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 4, 10), (-288, None)),\n",
       " (datetime.date(2005, 4, 11), (5062, None)),\n",
       " (datetime.date(2005, 4, 14), (6423, None)),\n",
       " (datetime.date(2005, 4, 15), (6459, 'San Diego')),\n",
       " (datetime.date(2005, 4, 16), (6002, 'San Diego')),\n",
       " (datetime.date(2005, 4, 17), (5322, 'San Diego')),\n",
       " (datetime.date(2005, 4, 18), (5600, None)),\n",
       " (datetime.date(2005, 4, 19), (6049, None)),\n",
       " (datetime.date(2005, 4, 21), (5977, None)),\n",
       " (datetime.date(2005, 4, 22), (6038, None))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyTrendCombined.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548109d",
   "metadata": {},
   "source": [
    "- You will see that the key is still the date, \n",
    "\n",
    "\n",
    "- but the value is now a tuple which contains values from the first RDD and the second RDD, Wherever the second RDD did not have a match for the keys in the first RDD\n",
    "\n",
    "\n",
    "- The reason we used the leftOuterJoin is we want to keep all the dates in our dataset whether or not there was a game on that day, if we had used a join directly then you would lose out on any dates which did not have a game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b74d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkGameDay(row):\n",
    "    if row[1][1]== None:\n",
    "        return (row[0], row[1][1], \"Regular Day\", row[1][0])\n",
    "    else:\n",
    "        return (row[0], row[1][1], \"Games Day\", row[1][0])\n",
    "    \n",
    "dailyTrendbyGames = dailyTrendCombined.map(checkGameDay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fe2e4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 4, 10), None, 'Regular Day', -288),\n",
       " (datetime.date(2005, 4, 11), None, 'Regular Day', 5062),\n",
       " (datetime.date(2005, 4, 14), None, 'Regular Day', 6423),\n",
       " (datetime.date(2005, 4, 15), 'San Diego', 'Games Day', 6459),\n",
       " (datetime.date(2005, 4, 16), 'San Diego', 'Games Day', 6002),\n",
       " (datetime.date(2005, 4, 17), 'San Diego', 'Games Day', 5322),\n",
       " (datetime.date(2005, 4, 18), None, 'Regular Day', 5600),\n",
       " (datetime.date(2005, 4, 19), None, 'Regular Day', 6049),\n",
       " (datetime.date(2005, 4, 21), None, 'Regular Day', 5977),\n",
       " (datetime.date(2005, 4, 22), None, 'Regular Day', 6038)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyTrendbyGames.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94d79357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2005, 7, 28), 'Cincinnati', 'Games Day', 7661),\n",
       " (datetime.date(2005, 7, 29), 'St. Louis', 'Games Day', 7499),\n",
       " (datetime.date(2005, 8, 12), 'NY Mets', 'Games Day', 7287),\n",
       " (datetime.date(2005, 7, 27), 'Cincinnati', 'Games Day', 7238),\n",
       " (datetime.date(2005, 9, 23), 'Pittsburgh', 'Games Day', 7175),\n",
       " (datetime.date(2005, 7, 26), 'Cincinnati', 'Games Day', 7163),\n",
       " (datetime.date(2005, 5, 20), 'LA Angels', 'Games Day', 7119),\n",
       " (datetime.date(2005, 8, 11), 'Philadelphia', 'Games Day', 7110),\n",
       " (datetime.date(2005, 9, 8), None, 'Regular Day', 7107),\n",
       " (datetime.date(2005, 9, 7), 'San Francisco', 'Games Day', 7082)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dailyTrendbyGames.sortBy(lambda x:-x[3]).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7241cd72",
   "metadata": {},
   "source": [
    "### CombineByKey\n",
    "\n",
    "- The combineByKey operation is a more general way to combine records with the same key,\n",
    "- like reduceByKey it is used to combine records which have the same key within an RDD,\n",
    "- but you have much more granular control over how these records can be combined\n",
    "\n",
    "\n",
    "- combineByKey requires 3 functions:\n",
    "  - createCombiner Function: This initializes a value when a key is seen for the first time within a partition.\n",
    "  \n",
    "  - merge Function: The second function is the merge function and this specifies how values with the same key should be combined for records which are present within a single partition.\n",
    "  \n",
    "  - mergeCombiners Function: Specifies how the results from each partition should be combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ccd7df",
   "metadata": {},
   "source": [
    "### Comparing average traffic on game days and non-game days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d572897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Regular Day', 5411.329787234043), ('Games Day', 5948.604938271605)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average on Game Day vs Non Game Day\n",
    "\n",
    "dailyTrendbyGames.map(lambda x:(x[2], x[3]))\\\n",
    "                 .combineByKey(lambda value : (value,1),\n",
    "                 lambda acc,value:(acc[0]+value,acc[1]+1),\\\n",
    "                 lambda acc1, acc2:(acc1[0]+acc2[0], acc1[1]+acc2[1]))\\\n",
    "                 .mapValues(lambda x:x[0]/x[1])\\\n",
    "                 .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f795c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10(ipykernel)",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
